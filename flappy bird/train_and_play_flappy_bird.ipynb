{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set the working directory\n",
    "os.chdir(\"D:\\\\RL_Finance\\\\RL sutton book\\\\flappy bird\")\n",
    "sys.path.append(\"D:/RL_Finance/RL sutton book/flappy_bird\")\n",
    "\n",
    "import torch\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "d:\\RL_Finance\\RL sutton book\\flappy bird\\agent.py:132: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state=torch.tensor(state, dtype=torch.float).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best reward 0.1 in Episode 1 - Model saved\n",
      "New best reward 0.2 in Episode 1 - Model saved\n",
      "New best reward 0.30000000000000004 in Episode 1 - Model saved\n",
      "New best reward 0.4 in Episode 1 - Model saved\n",
      "New best reward 0.5 in Episode 1 - Model saved\n",
      "New best reward 0.6 in Episode 1 - Model saved\n",
      "New best reward 0.7 in Episode 1 - Model saved\n",
      "New best reward 0.7999999999999999 in Episode 1 - Model saved\n",
      "New best reward 0.8999999999999999 in Episode 1 - Model saved\n",
      "New best reward 0.9999999999999999 in Episode 1 - Model saved\n",
      "New best reward 1.0999999999999999 in Episode 1 - Model saved\n",
      "New best reward 1.2 in Episode 1 - Model saved\n",
      "New best reward 1.3 in Episode 1 - Model saved\n",
      "New best reward 1.4000000000000001 in Episode 1 - Model saved\n",
      "New best reward 1.5000000000000002 in Episode 1 - Model saved\n",
      "New best reward 1.6000000000000003 in Episode 1 - Model saved\n",
      "New best reward 1.7000000000000004 in Episode 1 - Model saved\n",
      "New best reward 1.8000000000000005 in Episode 1 - Model saved\n",
      "New best reward 1.9000000000000006 in Episode 1 - Model saved\n",
      "New best reward 2.0000000000000004 in Episode 1 - Model saved\n",
      "New best reward 2.1000000000000005 in Episode 1 - Model saved\n",
      "New best reward 2.2000000000000006 in Episode 1 - Model saved\n",
      "New best reward 2.3000000000000007 in Episode 1 - Model saved\n",
      "New best reward 2.400000000000001 in Episode 1 - Model saved\n",
      "New best reward 2.500000000000001 in Episode 1 - Model saved\n",
      "New best reward 2.600000000000001 in Episode 1 - Model saved\n",
      "New best reward 2.700000000000001 in Episode 1 - Model saved\n",
      "New best reward 2.800000000000001 in Episode 1 - Model saved\n",
      "New best reward 2.9000000000000012 in Episode 1 - Model saved\n",
      "New best reward 3.0000000000000013 in Episode 1 - Model saved\n",
      "New best reward 3.1000000000000014 in Episode 1 - Model saved\n",
      "New best reward 3.2000000000000015 in Episode 1 - Model saved\n",
      "New best reward 3.3000000000000016 in Episode 1 - Model saved\n",
      "New best reward 3.4000000000000017 in Episode 1 - Model saved\n",
      "New best reward 3.5000000000000018 in Episode 1 - Model saved\n",
      "New best reward 3.600000000000002 in Episode 1 - Model saved\n",
      "New best reward 3.700000000000002 in Episode 6 - Model saved\n",
      "New best reward 3.800000000000002 in Episode 58 - Model saved\n",
      "New best reward 3.900000000000002 in Episode 58 - Model saved\n",
      "New best reward 4.000000000000002 in Episode 58 - Model saved\n",
      "New best reward 4.100000000000001 in Episode 58 - Model saved\n",
      "loss: 0.07702354341745377, episode: 100\n",
      "New best reward 4.200000000000001 in Episode 124 - Model saved\n",
      "New best reward 4.300000000000001 in Episode 124 - Model saved\n",
      "loss: 0.07557535916566849, episode: 200\n",
      "New best reward 4.4 in Episode 205 - Model saved\n",
      "New best reward 4.5 in Episode 205 - Model saved\n",
      "New best reward 4.6 in Episode 205 - Model saved\n",
      "New best reward 4.699999999999999 in Episode 205 - Model saved\n",
      "New best reward 4.799999999999999 in Episode 205 - Model saved\n",
      "New best reward 4.899999999999999 in Episode 205 - Model saved\n",
      "New best reward 5.799999999999998 in Episode 268 - Model saved\n",
      "loss: 0.13492490351200104, episode: 300\n",
      "loss: 0.10390839725732803, episode: 400\n",
      "New best reward 5.899999999999995 in Episode 447 - Model saved\n",
      "New best reward 5.999999999999995 in Episode 447 - Model saved\n",
      "New best reward 6.099999999999994 in Episode 447 - Model saved\n",
      "New best reward 6.199999999999994 in Episode 447 - Model saved\n",
      "New best reward 6.199999999999995 in Episode 487 - Model saved\n",
      "New best reward 6.2999999999999945 in Episode 487 - Model saved\n",
      "New best reward 6.399999999999994 in Episode 487 - Model saved\n",
      "New best reward 6.499999999999994 in Episode 487 - Model saved\n",
      "New best reward 6.599999999999993 in Episode 487 - Model saved\n",
      "New best reward 6.699999999999993 in Episode 487 - Model saved\n",
      "New best reward 6.799999999999993 in Episode 487 - Model saved\n",
      "New best reward 6.899999999999992 in Episode 487 - Model saved\n",
      "New best reward 6.999999999999992 in Episode 487 - Model saved\n",
      "New best reward 7.099999999999992 in Episode 487 - Model saved\n",
      "New best reward 7.199999999999991 in Episode 487 - Model saved\n",
      "New best reward 7.299999999999991 in Episode 487 - Model saved\n",
      "New best reward 7.399999999999991 in Episode 487 - Model saved\n",
      "New best reward 7.49999999999999 in Episode 487 - Model saved\n",
      "loss: 0.08776763081550598, episode: 500\n",
      "loss: 0.03608580678701401, episode: 600\n",
      "loss: 0.34006187319755554, episode: 700\n",
      "loss: 0.1455487608909607, episode: 800\n",
      "loss: 0.17555874586105347, episode: 900\n",
      "loss: 0.11322544515132904, episode: 1000\n",
      "loss: 0.05544445663690567, episode: 1100\n",
      "loss: 0.18765169382095337, episode: 1200\n",
      "New best reward 7.599999999999989 in Episode 1283 - Model saved\n",
      "New best reward 7.699999999999989 in Episode 1283 - Model saved\n",
      "New best reward 7.799999999999988 in Episode 1283 - Model saved\n",
      "New best reward 7.899999999999988 in Episode 1283 - Model saved\n",
      "New best reward 7.999999999999988 in Episode 1283 - Model saved\n",
      "New best reward 8.099999999999987 in Episode 1283 - Model saved\n",
      "New best reward 8.199999999999987 in Episode 1283 - Model saved\n",
      "New best reward 8.299999999999986 in Episode 1283 - Model saved\n",
      "loss: 0.06308700889348984, episode: 1300\n",
      "loss: 0.16161096096038818, episode: 1400\n",
      "loss: 0.14411777257919312, episode: 1500\n",
      "New best reward 8.499999999999984 in Episode 1552 - Model saved\n",
      "New best reward 8.599999999999978 in Episode 1552 - Model saved\n",
      "New best reward 8.699999999999978 in Episode 1552 - Model saved\n",
      "New best reward 8.799999999999978 in Episode 1552 - Model saved\n",
      "New best reward 8.899999999999977 in Episode 1552 - Model saved\n",
      "New best reward 8.999999999999977 in Episode 1552 - Model saved\n",
      "New best reward 9.099999999999977 in Episode 1552 - Model saved\n",
      "New best reward 9.199999999999976 in Episode 1552 - Model saved\n",
      "New best reward 9.299999999999976 in Episode 1552 - Model saved\n",
      "New best reward 9.399999999999975 in Episode 1552 - Model saved\n",
      "New best reward 9.499999999999975 in Episode 1552 - Model saved\n",
      "New best reward 9.599999999999975 in Episode 1552 - Model saved\n",
      "loss: 0.044412437826395035, episode: 1600\n",
      "loss: 0.07321640849113464, episode: 1700\n",
      "New best reward 9.599999999999984 in Episode 1777 - Model saved\n",
      "New best reward 9.699999999999983 in Episode 1777 - Model saved\n",
      "New best reward 9.799999999999983 in Episode 1777 - Model saved\n",
      "New best reward 9.899999999999983 in Episode 1777 - Model saved\n",
      "New best reward 9.999999999999982 in Episode 1777 - Model saved\n",
      "New best reward 10.099999999999982 in Episode 1777 - Model saved\n",
      "New best reward 10.199999999999982 in Episode 1777 - Model saved\n",
      "New best reward 10.299999999999981 in Episode 1777 - Model saved\n",
      "New best reward 10.39999999999998 in Episode 1777 - Model saved\n",
      "New best reward 10.49999999999998 in Episode 1777 - Model saved\n",
      "New best reward 10.59999999999998 in Episode 1777 - Model saved\n",
      "New best reward 10.69999999999998 in Episode 1777 - Model saved\n",
      "New best reward 10.79999999999998 in Episode 1777 - Model saved\n",
      "New best reward 10.899999999999979 in Episode 1777 - Model saved\n",
      "New best reward 10.999999999999979 in Episode 1777 - Model saved\n",
      "New best reward 11.099999999999978 in Episode 1777 - Model saved\n",
      "New best reward 11.199999999999978 in Episode 1777 - Model saved\n",
      "New best reward 11.299999999999978 in Episode 1777 - Model saved\n",
      "loss: 0.3373229503631592, episode: 1800\n",
      "loss: 0.09143219888210297, episode: 1900\n",
      "loss: 0.12677592039108276, episode: 2000\n",
      "loss: 0.10975019633769989, episode: 2100\n",
      "loss: 0.2174054980278015, episode: 2200\n",
      "loss: 0.0986073687672615, episode: 2300\n",
      "loss: 0.25743240118026733, episode: 2400\n",
      "loss: 0.038295943289995193, episode: 2500\n",
      "loss: 0.05180417373776436, episode: 2600\n",
      "loss: 0.05632774531841278, episode: 2700\n",
      "loss: 0.07930785417556763, episode: 2800\n",
      "loss: 0.0790490210056305, episode: 2900\n",
      "loss: 0.17032873630523682, episode: 3000\n",
      "loss: 0.03150501847267151, episode: 3100\n",
      "loss: 0.16619572043418884, episode: 3200\n",
      "loss: 0.05980947986245155, episode: 3300\n",
      "loss: 0.05903881788253784, episode: 3400\n",
      "loss: 0.09361612051725388, episode: 3500\n",
      "loss: 0.26020556688308716, episode: 3600\n",
      "loss: 0.14443060755729675, episode: 3700\n",
      "loss: 0.29587051272392273, episode: 3800\n",
      "loss: 0.05009226128458977, episode: 3900\n",
      "loss: 0.0643959790468216, episode: 4000\n",
      "loss: 0.10550612211227417, episode: 4100\n",
      "loss: 0.11667845398187637, episode: 4200\n",
      "loss: 0.1525166630744934, episode: 4300\n",
      "loss: 0.06963105499744415, episode: 4400\n",
      "loss: 0.10130070894956589, episode: 4500\n",
      "loss: 0.12981262803077698, episode: 4600\n",
      "loss: 0.10421532392501831, episode: 4700\n",
      "loss: 0.09194648265838623, episode: 4800\n",
      "loss: 0.07213939726352692, episode: 4900\n",
      "loss: 0.11986550688743591, episode: 5000\n",
      "loss: 0.1042223796248436, episode: 5100\n",
      "loss: 0.052057743072509766, episode: 5200\n",
      "loss: 0.21241998672485352, episode: 5300\n",
      "loss: 0.06952326744794846, episode: 5400\n",
      "loss: 0.270382821559906, episode: 5500\n",
      "loss: 0.21776896715164185, episode: 5600\n",
      "loss: 0.11578935384750366, episode: 5700\n",
      "loss: 0.09178335219621658, episode: 5800\n",
      "loss: 0.13516324758529663, episode: 5900\n",
      "loss: 0.12545311450958252, episode: 6000\n",
      "loss: 0.1541876345872879, episode: 6100\n",
      "loss: 0.13079166412353516, episode: 6200\n",
      "loss: 0.10486973822116852, episode: 6300\n",
      "loss: 0.10271428525447845, episode: 6400\n",
      "loss: 0.053991083055734634, episode: 6500\n",
      "loss: 0.12737539410591125, episode: 6600\n",
      "loss: 0.06158582121133804, episode: 6700\n",
      "loss: 0.10879090428352356, episode: 6800\n",
      "loss: 0.05810810253024101, episode: 6900\n",
      "loss: 0.0959118902683258, episode: 7000\n",
      "loss: 0.25074324011802673, episode: 7100\n",
      "loss: 0.1489640772342682, episode: 7200\n",
      "loss: 0.06417258083820343, episode: 7300\n",
      "loss: 0.11305010318756104, episode: 7400\n",
      "loss: 0.09743355214595795, episode: 7500\n",
      "loss: 0.10422354191541672, episode: 7600\n",
      "loss: 0.12704025208950043, episode: 7700\n",
      "loss: 0.10866400599479675, episode: 7800\n",
      "loss: 0.12876713275909424, episode: 7900\n",
      "loss: 0.16467538475990295, episode: 8000\n",
      "loss: 0.13249367475509644, episode: 8100\n",
      "loss: 0.18698498606681824, episode: 8200\n",
      "loss: 0.08385559171438217, episode: 8300\n",
      "loss: 0.0634722039103508, episode: 8400\n",
      "loss: 0.09731900691986084, episode: 8500\n",
      "loss: 0.12839947640895844, episode: 8600\n",
      "loss: 0.12541675567626953, episode: 8700\n",
      "loss: 0.09514038264751434, episode: 8800\n",
      "loss: 0.14628152549266815, episode: 8900\n",
      "loss: 0.11927010864019394, episode: 9000\n",
      "loss: 0.10462866723537445, episode: 9100\n",
      "loss: 0.10640669614076614, episode: 9200\n",
      "loss: 0.11944093555212021, episode: 9300\n",
      "loss: 0.08849017322063446, episode: 9400\n",
      "loss: 0.09722763299942017, episode: 9500\n",
      "loss: 0.09601160883903503, episode: 9600\n",
      "loss: 0.12650372087955475, episode: 9700\n",
      "loss: 0.14715877175331116, episode: 9800\n",
      "loss: 0.08425342291593552, episode: 9900\n",
      "loss: 0.09658624976873398, episode: 10000\n",
      "loss: 0.1787947118282318, episode: 10100\n",
      "loss: 0.14712335169315338, episode: 10200\n",
      "loss: 0.13799609243869781, episode: 10300\n",
      "loss: 0.15934203565120697, episode: 10400\n",
      "loss: 0.14504972100257874, episode: 10500\n",
      "loss: 0.17335224151611328, episode: 10600\n",
      "loss: 0.10209578275680542, episode: 10700\n",
      "loss: 0.14288491010665894, episode: 10800\n",
      "loss: 0.11990462243556976, episode: 10900\n",
      "loss: 0.1307096779346466, episode: 11000\n",
      "loss: 0.1316264271736145, episode: 11100\n",
      "loss: 0.07948314398527145, episode: 11200\n",
      "loss: 0.09354036301374435, episode: 11300\n",
      "loss: 0.12739302217960358, episode: 11400\n",
      "loss: 0.07073215395212173, episode: 11500\n",
      "loss: 0.06632935255765915, episode: 11600\n",
      "loss: 0.06370168179273605, episode: 11700\n",
      "loss: 0.03318383917212486, episode: 11800\n",
      "loss: 0.050391145050525665, episode: 11900\n",
      "loss: 0.12193726003170013, episode: 12000\n",
      "loss: 0.19944526255130768, episode: 12100\n",
      "loss: 0.19828270375728607, episode: 12200\n",
      "loss: 0.12646569311618805, episode: 12300\n",
      "loss: 0.06448937207460403, episode: 12400\n",
      "loss: 0.08309280872344971, episode: 12500\n",
      "loss: 0.07786239683628082, episode: 12600\n",
      "loss: 0.06011524051427841, episode: 12700\n",
      "loss: 0.07180718332529068, episode: 12800\n",
      "loss: 0.1093035489320755, episode: 12900\n",
      "loss: 0.10893061757087708, episode: 13000\n",
      "loss: 0.10976370424032211, episode: 13100\n",
      "loss: 0.12499264627695084, episode: 13200\n",
      "loss: 0.20029965043067932, episode: 13300\n",
      "loss: 0.08458998799324036, episode: 13400\n",
      "loss: 0.14897067844867706, episode: 13500\n",
      "loss: 0.14400914311408997, episode: 13600\n",
      "loss: 0.07425480335950851, episode: 13700\n",
      "loss: 0.23224899172782898, episode: 13800\n",
      "loss: 0.08190924674272537, episode: 13900\n",
      "loss: 0.31472048163414, episode: 14000\n",
      "loss: 0.20150519907474518, episode: 14100\n",
      "loss: 0.1412961781024933, episode: 14200\n",
      "loss: 0.27778902649879456, episode: 14300\n",
      "loss: 0.17165879905223846, episode: 14400\n",
      "loss: 0.14460238814353943, episode: 14500\n",
      "loss: 0.1275065839290619, episode: 14600\n",
      "loss: 0.0761883407831192, episode: 14700\n",
      "loss: 0.15062567591667175, episode: 14800\n",
      "loss: 0.2138819545507431, episode: 14900\n",
      "loss: 0.07564647495746613, episode: 15000\n",
      "loss: 0.03730008751153946, episode: 15100\n",
      "loss: 0.06635881960391998, episode: 15200\n",
      "loss: 0.2415156364440918, episode: 15300\n",
      "loss: 0.40797513723373413, episode: 15400\n",
      "loss: 0.22802439332008362, episode: 15500\n",
      "loss: 0.08030619472265244, episode: 15600\n",
      "loss: 0.16163374483585358, episode: 15700\n",
      "loss: 0.0415131114423275, episode: 15800\n",
      "loss: 0.22469085454940796, episode: 15900\n",
      "loss: 0.08589214086532593, episode: 16000\n",
      "loss: 0.17562374472618103, episode: 16100\n",
      "loss: 0.21881097555160522, episode: 16200\n",
      "loss: 0.22507718205451965, episode: 16300\n",
      "loss: 0.10578884184360504, episode: 16400\n",
      "loss: 0.1094316840171814, episode: 16500\n",
      "loss: 0.10368963330984116, episode: 16600\n",
      "loss: 0.15295138955116272, episode: 16700\n",
      "loss: 0.095838263630867, episode: 16800\n",
      "loss: 0.07635743170976639, episode: 16900\n",
      "loss: 0.09161399304866791, episode: 17000\n",
      "loss: 0.11439576745033264, episode: 17100\n",
      "loss: 0.10976485908031464, episode: 17200\n",
      "loss: 0.10781038552522659, episode: 17300\n",
      "loss: 0.2685285806655884, episode: 17400\n",
      "loss: 0.09156458079814911, episode: 17500\n",
      "loss: 0.13124015927314758, episode: 17600\n",
      "loss: 0.28258517384529114, episode: 17700\n",
      "loss: 0.19134539365768433, episode: 17800\n",
      "loss: 0.2986759543418884, episode: 17900\n",
      "loss: 0.23306800425052643, episode: 18000\n",
      "loss: 0.2072957456111908, episode: 18100\n",
      "loss: 0.08983460068702698, episode: 18200\n",
      "loss: 0.05294047296047211, episode: 18300\n",
      "loss: 0.228708878159523, episode: 18400\n",
      "loss: 0.05936254560947418, episode: 18500\n",
      "loss: 0.07340005040168762, episode: 18600\n",
      "loss: 0.09050226211547852, episode: 18700\n",
      "loss: 0.0821537896990776, episode: 18800\n",
      "loss: 0.19611725211143494, episode: 18900\n",
      "loss: 0.04467460513114929, episode: 19000\n",
      "loss: 0.07024550437927246, episode: 19100\n",
      "loss: 0.13447104394435883, episode: 19200\n",
      "loss: 0.07751293480396271, episode: 19300\n",
      "loss: 0.14156974852085114, episode: 19400\n",
      "loss: 0.09160077571868896, episode: 19500\n",
      "loss: 0.14183610677719116, episode: 19600\n",
      "loss: 0.09975118935108185, episode: 19700\n",
      "loss: 0.07585073262453079, episode: 19800\n",
      "loss: 0.2267034649848938, episode: 19900\n",
      "loss: 0.09634716808795929, episode: 20000\n",
      "loss: 0.08590053021907806, episode: 20100\n",
      "loss: 0.08403231203556061, episode: 20200\n",
      "loss: 0.04952050745487213, episode: 20300\n",
      "loss: 0.07661920040845871, episode: 20400\n",
      "loss: 0.06825463473796844, episode: 20500\n",
      "loss: 0.1158071979880333, episode: 20600\n",
      "loss: 0.13977836072444916, episode: 20700\n",
      "loss: 0.06892738491296768, episode: 20800\n",
      "loss: 0.1617075502872467, episode: 20900\n",
      "loss: 0.17420694231987, episode: 21000\n",
      "loss: 0.2600308656692505, episode: 21100\n",
      "loss: 0.09651289880275726, episode: 21200\n",
      "loss: 0.22872528433799744, episode: 21300\n",
      "loss: 0.04702182486653328, episode: 21400\n",
      "loss: 0.2047286182641983, episode: 21500\n",
      "loss: 0.1955302655696869, episode: 21600\n",
      "loss: 0.042376961559057236, episode: 21700\n",
      "loss: 0.08516371995210648, episode: 21800\n",
      "loss: 0.08655890077352524, episode: 21900\n",
      "loss: 0.14387348294258118, episode: 22000\n",
      "loss: 0.16417326033115387, episode: 22100\n",
      "loss: 0.16966381669044495, episode: 22200\n",
      "loss: 0.3362680673599243, episode: 22300\n",
      "loss: 0.12350955605506897, episode: 22400\n",
      "loss: 0.08406898379325867, episode: 22500\n",
      "loss: 0.18752576410770416, episode: 22600\n",
      "loss: 0.050864607095718384, episode: 22700\n",
      "loss: 0.057304512709379196, episode: 22800\n",
      "loss: 0.09412707388401031, episode: 22900\n",
      "loss: 0.2060975879430771, episode: 23000\n",
      "loss: 0.1749851256608963, episode: 23100\n",
      "loss: 0.11246530711650848, episode: 23200\n",
      "loss: 0.09843254834413528, episode: 23300\n",
      "loss: 0.4984527826309204, episode: 23400\n",
      "loss: 0.146840900182724, episode: 23500\n",
      "loss: 0.19906675815582275, episode: 23600\n",
      "loss: 0.1343189924955368, episode: 23700\n",
      "loss: 0.1859956681728363, episode: 23800\n",
      "loss: 0.09920389950275421, episode: 23900\n",
      "loss: 0.05352677404880524, episode: 24000\n",
      "loss: 0.22327542304992676, episode: 24100\n",
      "loss: 0.11309448629617691, episode: 24200\n",
      "loss: 0.08033435791730881, episode: 24300\n",
      "loss: 0.07066422700881958, episode: 24400\n",
      "loss: 0.07257656008005142, episode: 24500\n",
      "loss: 0.18439960479736328, episode: 24600\n",
      "loss: 0.08521538227796555, episode: 24700\n",
      "loss: 0.0704863965511322, episode: 24800\n",
      "loss: 0.15185144543647766, episode: 24900\n",
      "loss: 0.06630653887987137, episode: 25000\n",
      "loss: 0.05849932134151459, episode: 25100\n",
      "loss: 0.051958486437797546, episode: 25200\n",
      "loss: 0.07036395370960236, episode: 25300\n",
      "loss: 0.19992747902870178, episode: 25400\n",
      "loss: 0.25624319911003113, episode: 25500\n",
      "loss: 0.08311311900615692, episode: 25600\n",
      "loss: 0.11525087058544159, episode: 25700\n",
      "loss: 0.3379484713077545, episode: 25800\n",
      "loss: 0.25642701983451843, episode: 25900\n",
      "loss: 0.2000070959329605, episode: 26000\n",
      "loss: 0.2514025568962097, episode: 26100\n",
      "loss: 0.1192232072353363, episode: 26200\n",
      "loss: 0.2055058628320694, episode: 26300\n",
      "loss: 0.16899515688419342, episode: 26400\n",
      "loss: 0.08167716860771179, episode: 26500\n",
      "loss: 0.1813201755285263, episode: 26600\n",
      "loss: 0.038256824016571045, episode: 26700\n",
      "loss: 0.04075847566127777, episode: 26800\n",
      "loss: 0.1528347283601761, episode: 26900\n",
      "loss: 0.09518302977085114, episode: 27000\n",
      "loss: 0.05833550542593002, episode: 27100\n",
      "loss: 0.1644761860370636, episode: 27200\n",
      "loss: 0.051518477499485016, episode: 27300\n",
      "loss: 0.03602329641580582, episode: 27400\n",
      "loss: 0.21367235481739044, episode: 27500\n",
      "loss: 0.06293801963329315, episode: 27600\n",
      "loss: 0.10910002887248993, episode: 27700\n",
      "loss: 0.17846594750881195, episode: 27800\n",
      "loss: 0.11845991015434265, episode: 27900\n",
      "loss: 0.2657463550567627, episode: 28000\n",
      "loss: 0.22830350697040558, episode: 28100\n",
      "loss: 0.07019834220409393, episode: 28200\n",
      "loss: 0.16932366788387299, episode: 28300\n",
      "loss: 0.07487757503986359, episode: 28400\n",
      "loss: 0.10454689711332321, episode: 28500\n",
      "loss: 0.0576230064034462, episode: 28600\n",
      "loss: 0.12860113382339478, episode: 28700\n",
      "loss: 0.10476027429103851, episode: 28800\n",
      "loss: 0.10309614986181259, episode: 28900\n",
      "loss: 0.14739206433296204, episode: 29000\n",
      "loss: 0.07293186336755753, episode: 29100\n",
      "loss: 0.07716532051563263, episode: 29200\n",
      "loss: 0.05389932543039322, episode: 29300\n",
      "loss: 0.11415575444698334, episode: 29400\n",
      "loss: 0.15959662199020386, episode: 29500\n",
      "loss: 0.0959225669503212, episode: 29600\n",
      "loss: 0.04471483454108238, episode: 29700\n",
      "loss: 0.11825740337371826, episode: 29800\n",
      "loss: 0.05200209468603134, episode: 29900\n",
      "loss: 0.1649293750524521, episode: 30000\n",
      "loss: 0.2660754919052124, episode: 30100\n",
      "loss: 0.05427642911672592, episode: 30200\n",
      "loss: 0.18118196725845337, episode: 30300\n",
      "loss: 0.12575219571590424, episode: 30400\n",
      "loss: 0.04371257126331329, episode: 30500\n",
      "loss: 0.21893322467803955, episode: 30600\n",
      "loss: 0.20131103694438934, episode: 30700\n",
      "loss: 0.30276215076446533, episode: 30800\n",
      "loss: 0.12157837301492691, episode: 30900\n",
      "loss: 0.11737938225269318, episode: 31000\n",
      "loss: 0.22213104367256165, episode: 31100\n",
      "loss: 0.15233908593654633, episode: 31200\n",
      "loss: 0.15466418862342834, episode: 31300\n",
      "loss: 0.46077606081962585, episode: 31400\n",
      "loss: 0.16783443093299866, episode: 31500\n",
      "loss: 0.2504127323627472, episode: 31600\n",
      "loss: 0.26461145281791687, episode: 31700\n",
      "loss: 0.0569949746131897, episode: 31800\n",
      "loss: 0.0674016997218132, episode: 31900\n",
      "loss: 0.10445018112659454, episode: 32000\n",
      "loss: 0.05496363714337349, episode: 32100\n",
      "loss: 0.26172515749931335, episode: 32200\n",
      "loss: 0.05961747094988823, episode: 32300\n",
      "loss: 0.05181492865085602, episode: 32400\n",
      "loss: 0.052308790385723114, episode: 32500\n",
      "loss: 0.17195338010787964, episode: 32600\n",
      "loss: 0.14721554517745972, episode: 32700\n",
      "loss: 0.0806557759642601, episode: 32800\n",
      "loss: 0.0745687186717987, episode: 32900\n",
      "loss: 0.08287693560123444, episode: 33000\n",
      "loss: 0.046416543424129486, episode: 33100\n",
      "loss: 0.2792092263698578, episode: 33200\n",
      "loss: 0.32626649737358093, episode: 33300\n",
      "loss: 0.0992933064699173, episode: 33400\n",
      "loss: 0.09216807782649994, episode: 33500\n",
      "loss: 0.20332786440849304, episode: 33600\n",
      "loss: 0.16680726408958435, episode: 33700\n",
      "loss: 0.16802933812141418, episode: 33800\n",
      "loss: 0.17318828403949738, episode: 33900\n",
      "loss: 0.058102916926145554, episode: 34000\n",
      "loss: 0.16603751480579376, episode: 34100\n",
      "loss: 0.05614309757947922, episode: 34200\n",
      "loss: 0.08796579390764236, episode: 34300\n",
      "loss: 0.17477573454380035, episode: 34400\n",
      "loss: 0.12316203117370605, episode: 34500\n",
      "loss: 0.17826411128044128, episode: 34600\n",
      "loss: 0.09971180558204651, episode: 34700\n",
      "loss: 0.1134004071354866, episode: 34800\n",
      "loss: 0.19771616160869598, episode: 34900\n",
      "loss: 0.15574802458286285, episode: 35000\n",
      "loss: 0.046037301421165466, episode: 35100\n",
      "loss: 0.03046923503279686, episode: 35200\n",
      "loss: 0.12352079153060913, episode: 35300\n",
      "loss: 0.1170121505856514, episode: 35400\n",
      "loss: 0.05371575802564621, episode: 35500\n",
      "loss: 0.07853244245052338, episode: 35600\n",
      "loss: 0.0369698703289032, episode: 35700\n",
      "loss: 0.0760921984910965, episode: 35800\n",
      "loss: 0.14244291186332703, episode: 35900\n",
      "loss: 0.07400162518024445, episode: 36000\n",
      "loss: 0.09155093133449554, episode: 36100\n",
      "loss: 0.18289008736610413, episode: 36200\n",
      "loss: 0.19604161381721497, episode: 36300\n",
      "loss: 0.13482554256916046, episode: 36400\n",
      "loss: 0.05663108080625534, episode: 36500\n",
      "loss: 0.03709159791469574, episode: 36600\n",
      "loss: 0.17438217997550964, episode: 36700\n",
      "loss: 0.19513891637325287, episode: 36800\n",
      "loss: 0.1425492763519287, episode: 36900\n",
      "loss: 0.19193993508815765, episode: 37000\n",
      "loss: 0.12089770287275314, episode: 37100\n",
      "loss: 0.16577541828155518, episode: 37200\n",
      "loss: 0.18102017045021057, episode: 37300\n",
      "loss: 0.05854747071862221, episode: 37400\n",
      "loss: 0.06998950988054276, episode: 37500\n",
      "loss: 0.24798688292503357, episode: 37600\n",
      "loss: 0.04234295338392258, episode: 37700\n",
      "loss: 0.052301254123449326, episode: 37800\n",
      "loss: 0.3556167185306549, episode: 37900\n",
      "loss: 0.20796401798725128, episode: 38000\n",
      "loss: 0.147457554936409, episode: 38100\n",
      "loss: 0.15547847747802734, episode: 38200\n",
      "loss: 0.073529914021492, episode: 38300\n",
      "loss: 0.2781105637550354, episode: 38400\n",
      "loss: 0.0761917382478714, episode: 38500\n",
      "loss: 0.20096592605113983, episode: 38600\n",
      "loss: 0.1759641170501709, episode: 38700\n",
      "loss: 0.18801957368850708, episode: 38800\n",
      "loss: 0.30569082498550415, episode: 38900\n",
      "loss: 0.2691691517829895, episode: 39000\n",
      "loss: 0.2288140505552292, episode: 39100\n",
      "loss: 0.1876373291015625, episode: 39200\n",
      "loss: 0.12220603227615356, episode: 39300\n",
      "loss: 0.18791362643241882, episode: 39400\n",
      "loss: 0.058445677161216736, episode: 39500\n",
      "loss: 0.05712413787841797, episode: 39600\n",
      "loss: 0.1988777369260788, episode: 39700\n",
      "loss: 0.24841062724590302, episode: 39800\n",
      "loss: 0.38778966665267944, episode: 39900\n",
      "loss: 0.15707972645759583, episode: 40000\n",
      "loss: 0.22487403452396393, episode: 40100\n",
      "loss: 0.22972150146961212, episode: 40200\n",
      "loss: 0.09351497143507004, episode: 40300\n",
      "loss: 0.2042011320590973, episode: 40400\n",
      "loss: 0.2522290349006653, episode: 40500\n",
      "loss: 0.2582232654094696, episode: 40600\n",
      "loss: 0.17025822401046753, episode: 40700\n",
      "loss: 0.2201024442911148, episode: 40800\n",
      "loss: 0.07650545239448547, episode: 40900\n",
      "loss: 0.2069077044725418, episode: 41000\n",
      "loss: 0.0633295327425003, episode: 41100\n",
      "loss: 0.19157998263835907, episode: 41200\n",
      "loss: 0.10411186516284943, episode: 41300\n",
      "loss: 0.06037305295467377, episode: 41400\n",
      "loss: 0.10544172674417496, episode: 41500\n",
      "loss: 0.06914542615413666, episode: 41600\n",
      "loss: 0.06090668961405754, episode: 41700\n",
      "loss: 0.0591280423104763, episode: 41800\n",
      "loss: 0.11004909873008728, episode: 41900\n",
      "loss: 0.05855930596590042, episode: 42000\n",
      "loss: 0.12855717539787292, episode: 42100\n",
      "loss: 0.22150686383247375, episode: 42200\n",
      "loss: 0.07870089262723923, episode: 42300\n",
      "loss: 0.17920036613941193, episode: 42400\n",
      "loss: 0.04685482010245323, episode: 42500\n",
      "loss: 0.08721400797367096, episode: 42600\n",
      "loss: 0.055832188576459885, episode: 42700\n",
      "loss: 0.3837197721004486, episode: 42800\n",
      "loss: 0.1691475212574005, episode: 42900\n",
      "loss: 0.21163210272789001, episode: 43000\n",
      "loss: 0.19472776353359222, episode: 43100\n",
      "loss: 0.09045647084712982, episode: 43200\n",
      "loss: 0.34774017333984375, episode: 43300\n",
      "loss: 0.05074751377105713, episode: 43400\n",
      "loss: 0.08200818300247192, episode: 43500\n",
      "loss: 0.07748213410377502, episode: 43600\n",
      "loss: 0.18100497126579285, episode: 43700\n",
      "loss: 0.08085460960865021, episode: 43800\n",
      "loss: 0.0902843177318573, episode: 43900\n",
      "loss: 0.25371235609054565, episode: 44000\n",
      "loss: 0.10156352818012238, episode: 44100\n",
      "loss: 0.08443145453929901, episode: 44200\n",
      "loss: 0.15496043860912323, episode: 44300\n",
      "loss: 0.266021728515625, episode: 44400\n",
      "loss: 0.10422008484601974, episode: 44500\n",
      "loss: 0.09456942975521088, episode: 44600\n",
      "loss: 0.22925414144992828, episode: 44700\n",
      "loss: 0.20408646762371063, episode: 44800\n",
      "loss: 0.06882178038358688, episode: 44900\n",
      "loss: 0.1628684401512146, episode: 45000\n",
      "loss: 0.048505935817956924, episode: 45100\n",
      "loss: 0.07390531152486801, episode: 45200\n",
      "loss: 0.07519032806158066, episode: 45300\n",
      "loss: 0.22647574543952942, episode: 45400\n",
      "loss: 0.11204983294010162, episode: 45500\n",
      "loss: 0.12154704332351685, episode: 45600\n",
      "loss: 0.31401097774505615, episode: 45700\n",
      "loss: 0.05019319802522659, episode: 45800\n",
      "loss: 0.17993368208408356, episode: 45900\n",
      "loss: 0.06717979162931442, episode: 46000\n",
      "loss: 0.04660061374306679, episode: 46100\n",
      "loss: 0.1162191778421402, episode: 46200\n",
      "loss: 0.1761164665222168, episode: 46300\n",
      "loss: 0.11817653477191925, episode: 46400\n",
      "loss: 0.2102605700492859, episode: 46500\n",
      "loss: 0.040341317653656006, episode: 46600\n",
      "loss: 0.2065708488225937, episode: 46700\n",
      "loss: 0.08363159000873566, episode: 46800\n",
      "loss: 0.072528176009655, episode: 46900\n",
      "loss: 0.05627606064081192, episode: 47000\n",
      "loss: 0.20817464590072632, episode: 47100\n",
      "loss: 0.08960996568202972, episode: 47200\n",
      "loss: 0.13156579434871674, episode: 47300\n",
      "loss: 0.08956270664930344, episode: 47400\n",
      "loss: 0.43572306632995605, episode: 47500\n",
      "loss: 0.18119080364704132, episode: 47600\n",
      "loss: 0.09434555470943451, episode: 47700\n",
      "loss: 0.1288406401872635, episode: 47800\n",
      "loss: 0.26458093523979187, episode: 47900\n",
      "loss: 0.08361731469631195, episode: 48000\n",
      "loss: 0.2714204490184784, episode: 48100\n",
      "loss: 0.203183114528656, episode: 48200\n",
      "loss: 0.20659443736076355, episode: 48300\n",
      "loss: 0.22323763370513916, episode: 48400\n",
      "loss: 0.13904669880867004, episode: 48500\n",
      "loss: 0.0914619043469429, episode: 48600\n",
      "loss: 0.11820143461227417, episode: 48700\n",
      "loss: 0.34412407875061035, episode: 48800\n",
      "loss: 0.10380028188228607, episode: 48900\n",
      "loss: 0.11431625485420227, episode: 49000\n",
      "loss: 0.08651035279035568, episode: 49100\n",
      "loss: 0.2400462031364441, episode: 49200\n",
      "loss: 0.13831306993961334, episode: 49300\n",
      "New best reward 11.299999999999981 in Episode 49321 - Model saved\n",
      "New best reward 11.39999999999998 in Episode 49321 - Model saved\n",
      "New best reward 11.49999999999998 in Episode 49321 - Model saved\n",
      "New best reward 11.59999999999998 in Episode 49321 - Model saved\n",
      "New best reward 11.69999999999998 in Episode 49321 - Model saved\n",
      "New best reward 11.79999999999998 in Episode 49321 - Model saved\n",
      "New best reward 11.899999999999979 in Episode 49321 - Model saved\n",
      "New best reward 11.999999999999979 in Episode 49321 - Model saved\n",
      "New best reward 12.099999999999978 in Episode 49321 - Model saved\n",
      "New best reward 12.199999999999978 in Episode 49321 - Model saved\n",
      "New best reward 12.299999999999978 in Episode 49321 - Model saved\n",
      "New best reward 12.399999999999977 in Episode 49321 - Model saved\n",
      "New best reward 12.499999999999977 in Episode 49321 - Model saved\n",
      "New best reward 12.599999999999977 in Episode 49321 - Model saved\n",
      "New best reward 12.699999999999976 in Episode 49321 - Model saved\n",
      "New best reward 12.799999999999976 in Episode 49321 - Model saved\n",
      "New best reward 12.899999999999975 in Episode 49321 - Model saved\n",
      "New best reward 12.999999999999975 in Episode 49321 - Model saved\n",
      "New best reward 13.099999999999975 in Episode 49321 - Model saved\n",
      "New best reward 13.199999999999974 in Episode 49321 - Model saved\n",
      "New best reward 13.299999999999974 in Episode 49321 - Model saved\n",
      "New best reward 13.399999999999974 in Episode 49321 - Model saved\n",
      "New best reward 13.499999999999973 in Episode 49321 - Model saved\n",
      "New best reward 13.599999999999973 in Episode 49321 - Model saved\n",
      "loss: 0.10521268844604492, episode: 49400\n",
      "loss: 0.07835812866687775, episode: 49500\n",
      "loss: 0.045188020914793015, episode: 49600\n",
      "loss: 0.05494343489408493, episode: 49700\n",
      "loss: 0.0670439600944519, episode: 49800\n",
      "loss: 0.152060404419899, episode: 49900\n",
      "loss: 0.051165442913770676, episode: 50000\n",
      "loss: 0.09416719526052475, episode: 50100\n",
      "loss: 0.10840614140033722, episode: 50200\n",
      "loss: 0.08530986309051514, episode: 50300\n",
      "loss: 0.37242162227630615, episode: 50400\n",
      "loss: 0.48046332597732544, episode: 50500\n",
      "loss: 0.11252366751432419, episode: 50600\n",
      "loss: 0.167840838432312, episode: 50700\n",
      "loss: 0.043770335614681244, episode: 50800\n",
      "loss: 0.21765488386154175, episode: 50900\n",
      "loss: 0.2419966757297516, episode: 51000\n",
      "loss: 0.04180506616830826, episode: 51100\n",
      "loss: 0.05976708233356476, episode: 51200\n",
      "loss: 0.11091380566358566, episode: 51300\n",
      "loss: 0.15009567141532898, episode: 51400\n",
      "loss: 0.17566874623298645, episode: 51500\n",
      "loss: 0.1964196413755417, episode: 51600\n",
      "loss: 0.2550761103630066, episode: 51700\n",
      "loss: 0.07653898000717163, episode: 51800\n",
      "loss: 0.06925312429666519, episode: 51900\n",
      "loss: 0.14011713862419128, episode: 52000\n",
      "loss: 0.2686837911605835, episode: 52100\n",
      "loss: 0.3635004162788391, episode: 52200\n",
      "loss: 0.25708702206611633, episode: 52300\n",
      "loss: 0.12725043296813965, episode: 52400\n",
      "loss: 0.05771341919898987, episode: 52500\n",
      "loss: 0.10607682913541794, episode: 52600\n",
      "loss: 0.07176844775676727, episode: 52700\n",
      "loss: 0.45547664165496826, episode: 52800\n",
      "loss: 0.11017665266990662, episode: 52900\n",
      "loss: 0.030677814036607742, episode: 53000\n",
      "loss: 0.15570151805877686, episode: 53100\n",
      "loss: 0.30157405138015747, episode: 53200\n",
      "loss: 0.1925273835659027, episode: 53300\n",
      "loss: 0.15856200456619263, episode: 53400\n",
      "loss: 0.25406572222709656, episode: 53500\n",
      "loss: 0.0641481876373291, episode: 53600\n",
      "loss: 0.1848166286945343, episode: 53700\n",
      "loss: 0.03945120796561241, episode: 53800\n",
      "loss: 0.23954038321971893, episode: 53900\n",
      "loss: 0.06743544340133667, episode: 54000\n",
      "loss: 0.3095495104789734, episode: 54100\n",
      "loss: 0.20654071867465973, episode: 54200\n",
      "loss: 0.07832081615924835, episode: 54300\n",
      "loss: 0.121265709400177, episode: 54400\n",
      "loss: 0.17070399224758148, episode: 54500\n",
      "loss: 0.2346273809671402, episode: 54600\n",
      "loss: 0.2554430663585663, episode: 54700\n",
      "loss: 0.09622472524642944, episode: 54800\n",
      "loss: 0.06517402082681656, episode: 54900\n",
      "loss: 0.19540028274059296, episode: 55000\n",
      "loss: 0.3937406539916992, episode: 55100\n",
      "loss: 0.1841590851545334, episode: 55200\n",
      "loss: 0.18777111172676086, episode: 55300\n",
      "loss: 0.07223711907863617, episode: 55400\n",
      "loss: 0.06881029903888702, episode: 55500\n",
      "loss: 0.17238891124725342, episode: 55600\n",
      "loss: 0.10852314531803131, episode: 55700\n",
      "loss: 0.06748228520154953, episode: 55800\n",
      "loss: 0.05069155991077423, episode: 55900\n",
      "loss: 0.36044037342071533, episode: 56000\n",
      "loss: 0.056844569742679596, episode: 56100\n",
      "loss: 0.06908795982599258, episode: 56200\n",
      "loss: 0.1493629515171051, episode: 56300\n",
      "loss: 0.04318159446120262, episode: 56400\n",
      "loss: 0.18447484076023102, episode: 56500\n",
      "loss: 0.058189623057842255, episode: 56600\n",
      "loss: 0.05817846581339836, episode: 56700\n",
      "loss: 0.32108426094055176, episode: 56800\n",
      "loss: 0.06302934885025024, episode: 56900\n",
      "loss: 0.0781295895576477, episode: 57000\n",
      "loss: 0.05072212219238281, episode: 57100\n",
      "loss: 0.06565146148204803, episode: 57200\n",
      "loss: 0.23434409499168396, episode: 57300\n",
      "loss: 0.23350881040096283, episode: 57400\n",
      "loss: 0.07202450186014175, episode: 57500\n",
      "loss: 0.08156058192253113, episode: 57600\n",
      "loss: 0.132808119058609, episode: 57700\n",
      "loss: 0.2049582451581955, episode: 57800\n",
      "loss: 0.04056607931852341, episode: 57900\n",
      "loss: 0.10212308168411255, episode: 58000\n",
      "loss: 0.1136058047413826, episode: 58100\n",
      "loss: 0.10623019933700562, episode: 58200\n",
      "loss: 0.03542686253786087, episode: 58300\n",
      "loss: 0.16442462801933289, episode: 58400\n",
      "loss: 0.060415420681238174, episode: 58500\n",
      "loss: 0.1591632068157196, episode: 58600\n",
      "loss: 0.1720827966928482, episode: 58700\n",
      "loss: 0.08135095983743668, episode: 58800\n",
      "loss: 0.18948474526405334, episode: 58900\n",
      "loss: 0.29355958104133606, episode: 59000\n",
      "loss: 0.06718002259731293, episode: 59100\n",
      "loss: 0.17797094583511353, episode: 59200\n",
      "loss: 0.07937167584896088, episode: 59300\n",
      "loss: 0.1547955870628357, episode: 59400\n",
      "loss: 0.04097072035074234, episode: 59500\n",
      "loss: 0.4909932017326355, episode: 59600\n",
      "loss: 0.06968071311712265, episode: 59700\n",
      "loss: 0.29361647367477417, episode: 59800\n",
      "loss: 0.06475990265607834, episode: 59900\n",
      "loss: 0.06876975297927856, episode: 60000\n",
      "loss: 0.046951182186603546, episode: 60100\n",
      "loss: 0.2882218062877655, episode: 60200\n",
      "loss: 0.04690002650022507, episode: 60300\n",
      "loss: 0.05819987505674362, episode: 60400\n",
      "loss: 0.13826681673526764, episode: 60500\n",
      "loss: 0.08473293483257294, episode: 60600\n",
      "loss: 0.17428773641586304, episode: 60700\n",
      "loss: 0.06931604444980621, episode: 60800\n",
      "loss: 0.09051041305065155, episode: 60900\n",
      "loss: 0.22910453379154205, episode: 61000\n",
      "loss: 0.18333137035369873, episode: 61100\n",
      "New best reward 14.19999999999995 in Episode 61183 - Model saved\n",
      "New best reward 14.29999999999995 in Episode 61183 - Model saved\n",
      "New best reward 14.399999999999945 in Episode 61183 - Model saved\n",
      "New best reward 14.499999999999945 in Episode 61183 - Model saved\n",
      "New best reward 14.599999999999945 in Episode 61183 - Model saved\n",
      "New best reward 14.699999999999944 in Episode 61183 - Model saved\n",
      "New best reward 14.799999999999944 in Episode 61183 - Model saved\n",
      "New best reward 14.899999999999944 in Episode 61183 - Model saved\n",
      "New best reward 14.999999999999943 in Episode 61183 - Model saved\n",
      "New best reward 15.099999999999943 in Episode 61183 - Model saved\n",
      "New best reward 15.199999999999942 in Episode 61183 - Model saved\n",
      "New best reward 15.299999999999942 in Episode 61183 - Model saved\n",
      "New best reward 15.399999999999931 in Episode 61183 - Model saved\n",
      "New best reward 15.49999999999993 in Episode 61183 - Model saved\n",
      "New best reward 15.59999999999993 in Episode 61183 - Model saved\n",
      "New best reward 15.69999999999993 in Episode 61183 - Model saved\n",
      "New best reward 15.79999999999993 in Episode 61183 - Model saved\n",
      "New best reward 15.89999999999993 in Episode 61183 - Model saved\n",
      "New best reward 15.999999999999929 in Episode 61183 - Model saved\n",
      "New best reward 16.09999999999993 in Episode 61183 - Model saved\n",
      "New best reward 16.199999999999932 in Episode 61183 - Model saved\n",
      "New best reward 16.299999999999933 in Episode 61183 - Model saved\n",
      "New best reward 16.399999999999935 in Episode 61183 - Model saved\n",
      "New best reward 16.499999999999936 in Episode 61183 - Model saved\n",
      "New best reward 16.599999999999937 in Episode 61183 - Model saved\n",
      "New best reward 17.099999999999937 in Episode 61183 - Model saved\n",
      "New best reward 17.09999999999995 in Episode 61183 - Model saved\n",
      "New best reward 17.199999999999953 in Episode 61183 - Model saved\n",
      "New best reward 17.299999999999955 in Episode 61183 - Model saved\n",
      "New best reward 17.399999999999956 in Episode 61183 - Model saved\n",
      "New best reward 17.399999999999974 in Episode 61183 - Model saved\n",
      "New best reward 17.499999999999975 in Episode 61183 - Model saved\n",
      "New best reward 17.599999999999977 in Episode 61183 - Model saved\n",
      "New best reward 17.699999999999978 in Episode 61183 - Model saved\n",
      "New best reward 17.79999999999998 in Episode 61183 - Model saved\n",
      "New best reward 17.89999999999998 in Episode 61183 - Model saved\n",
      "New best reward 17.9 in Episode 61183 - Model saved\n",
      "New best reward 18.0 in Episode 61183 - Model saved\n",
      "New best reward 18.1 in Episode 61183 - Model saved\n",
      "New best reward 18.200000000000003 in Episode 61183 - Model saved\n",
      "New best reward 18.300000000000004 in Episode 61183 - Model saved\n",
      "New best reward 18.400000000000006 in Episode 61183 - Model saved\n",
      "New best reward 18.500000000000007 in Episode 61183 - Model saved\n",
      "New best reward 18.60000000000001 in Episode 61183 - Model saved\n",
      "New best reward 18.70000000000001 in Episode 61183 - Model saved\n",
      "New best reward 18.80000000000001 in Episode 61183 - Model saved\n",
      "New best reward 18.900000000000013 in Episode 61183 - Model saved\n",
      "New best reward 19.000000000000014 in Episode 61183 - Model saved\n",
      "New best reward 19.100000000000016 in Episode 61183 - Model saved\n",
      "loss: 0.07710875570774078, episode: 61200\n",
      "loss: 0.2753152847290039, episode: 61300\n",
      "loss: 0.09973077476024628, episode: 61400\n",
      "loss: 0.20582164824008942, episode: 61500\n",
      "loss: 0.09296592324972153, episode: 61600\n",
      "loss: 0.04695595055818558, episode: 61700\n",
      "loss: 0.0633549690246582, episode: 61800\n",
      "New best reward 19.199999999999964 in Episode 61854 - Model saved\n",
      "New best reward 20.09999999999997 in Episode 61854 - Model saved\n",
      "New best reward 20.099999999999984 in Episode 61854 - Model saved\n",
      "New best reward 20.199999999999985 in Episode 61854 - Model saved\n",
      "New best reward 20.299999999999986 in Episode 61854 - Model saved\n",
      "New best reward 20.399999999999988 in Episode 61854 - Model saved\n",
      "New best reward 20.49999999999999 in Episode 61854 - Model saved\n",
      "New best reward 20.59999999999999 in Episode 61854 - Model saved\n",
      "New best reward 20.699999999999992 in Episode 61854 - Model saved\n",
      "New best reward 20.799999999999994 in Episode 61854 - Model saved\n",
      "New best reward 20.899999999999995 in Episode 61854 - Model saved\n",
      "New best reward 20.999999999999996 in Episode 61854 - Model saved\n",
      "New best reward 21.099999999999998 in Episode 61854 - Model saved\n",
      "New best reward 21.2 in Episode 61854 - Model saved\n",
      "New best reward 21.3 in Episode 61854 - Model saved\n",
      "New best reward 21.400000000000002 in Episode 61854 - Model saved\n",
      "New best reward 21.500000000000004 in Episode 61854 - Model saved\n",
      "New best reward 21.600000000000005 in Episode 61854 - Model saved\n",
      "New best reward 21.700000000000006 in Episode 61854 - Model saved\n",
      "New best reward 21.800000000000008 in Episode 61854 - Model saved\n",
      "New best reward 21.90000000000001 in Episode 61854 - Model saved\n",
      "New best reward 22.00000000000001 in Episode 61854 - Model saved\n",
      "New best reward 22.100000000000012 in Episode 61854 - Model saved\n",
      "New best reward 22.10000000000002 in Episode 61854 - Model saved\n",
      "New best reward 22.20000000000002 in Episode 61854 - Model saved\n",
      "New best reward 22.70000000000002 in Episode 61854 - Model saved\n",
      "New best reward 22.700000000000035 in Episode 61854 - Model saved\n",
      "New best reward 22.800000000000036 in Episode 61854 - Model saved\n",
      "New best reward 22.900000000000038 in Episode 61854 - Model saved\n",
      "New best reward 23.00000000000004 in Episode 61854 - Model saved\n",
      "loss: 0.06036604940891266, episode: 61900\n",
      "loss: 0.14006873965263367, episode: 62000\n",
      "loss: 0.05565928667783737, episode: 62100\n",
      "loss: 0.12661965191364288, episode: 62200\n",
      "loss: 0.04982259124517441, episode: 62300\n",
      "loss: 0.19958257675170898, episode: 62400\n",
      "loss: 0.22843125462532043, episode: 62500\n",
      "loss: 0.06837165355682373, episode: 62600\n",
      "loss: 0.13365526497364044, episode: 62700\n",
      "loss: 0.1483815610408783, episode: 62800\n",
      "loss: 0.03418424353003502, episode: 62900\n",
      "loss: 0.11075783520936966, episode: 63000\n",
      "loss: 0.14122167229652405, episode: 63100\n",
      "loss: 0.11695992946624756, episode: 63200\n",
      "loss: 0.09130312502384186, episode: 63300\n",
      "loss: 0.24332395195960999, episode: 63400\n",
      "loss: 0.04686925560235977, episode: 63500\n",
      "loss: 0.3228696286678314, episode: 63600\n",
      "loss: 0.09275946766138077, episode: 63700\n",
      "loss: 0.08560268580913544, episode: 63800\n",
      "loss: 0.04630209505558014, episode: 63900\n",
      "loss: 0.13985872268676758, episode: 64000\n",
      "loss: 0.24055364727973938, episode: 64100\n",
      "loss: 0.19126777350902557, episode: 64200\n",
      "loss: 0.19216755032539368, episode: 64300\n",
      "loss: 0.12101483345031738, episode: 64400\n",
      "loss: 0.17283008992671967, episode: 64500\n",
      "loss: 0.17320403456687927, episode: 64600\n",
      "loss: 0.30975139141082764, episode: 64700\n",
      "loss: 0.0799764096736908, episode: 64800\n",
      "loss: 0.13236019015312195, episode: 64900\n",
      "loss: 0.2443714588880539, episode: 65000\n",
      "loss: 0.11542532593011856, episode: 65100\n",
      "loss: 0.283948689699173, episode: 65200\n",
      "loss: 0.2937496304512024, episode: 65300\n",
      "loss: 0.07617150247097015, episode: 65400\n",
      "loss: 0.23257645964622498, episode: 65500\n",
      "loss: 0.12580440938472748, episode: 65600\n",
      "loss: 0.12225194275379181, episode: 65700\n",
      "loss: 0.07260057330131531, episode: 65800\n",
      "loss: 0.09941309690475464, episode: 65900\n",
      "loss: 0.09161924570798874, episode: 66000\n",
      "loss: 0.14562508463859558, episode: 66100\n",
      "loss: 0.2834354639053345, episode: 66200\n",
      "loss: 0.1176275834441185, episode: 66300\n",
      "loss: 0.04796203598380089, episode: 66400\n",
      "loss: 0.29250025749206543, episode: 66500\n",
      "loss: 0.2640205919742584, episode: 66600\n",
      "loss: 0.18361902236938477, episode: 66700\n",
      "loss: 0.059315770864486694, episode: 66800\n",
      "loss: 0.37992188334465027, episode: 66900\n",
      "loss: 0.11476923525333405, episode: 67000\n",
      "loss: 0.27743685245513916, episode: 67100\n",
      "loss: 0.3782583773136139, episode: 67200\n",
      "loss: 0.37043052911758423, episode: 67300\n",
      "loss: 0.05075901001691818, episode: 67400\n",
      "loss: 0.05687721073627472, episode: 67500\n",
      "loss: 0.171955406665802, episode: 67600\n",
      "loss: 0.22656580805778503, episode: 67700\n",
      "loss: 0.10261134058237076, episode: 67800\n",
      "loss: 0.1723191738128662, episode: 67900\n",
      "loss: 0.0879409983754158, episode: 68000\n",
      "loss: 0.05224476754665375, episode: 68100\n",
      "loss: 0.08331998437643051, episode: 68200\n",
      "loss: 0.02475631982088089, episode: 68300\n",
      "loss: 0.24361103773117065, episode: 68400\n",
      "loss: 0.13610200583934784, episode: 68500\n",
      "loss: 0.20000958442687988, episode: 68600\n",
      "loss: 0.046274881809949875, episode: 68700\n",
      "loss: 0.06141219288110733, episode: 68800\n",
      "loss: 0.23167943954467773, episode: 68900\n",
      "loss: 0.16063454747200012, episode: 69000\n",
      "loss: 0.07386459410190582, episode: 69100\n",
      "loss: 0.16754885017871857, episode: 69200\n",
      "loss: 0.04724004119634628, episode: 69300\n",
      "loss: 0.14488127827644348, episode: 69400\n",
      "loss: 0.1643628478050232, episode: 69500\n",
      "loss: 0.1170487254858017, episode: 69600\n",
      "loss: 0.1652444303035736, episode: 69700\n",
      "loss: 0.047358740121126175, episode: 69800\n",
      "loss: 0.03801598772406578, episode: 69900\n",
      "loss: 0.16708765923976898, episode: 70000\n",
      "loss: 0.1795354187488556, episode: 70100\n",
      "loss: 0.21371519565582275, episode: 70200\n",
      "loss: 0.04862638935446739, episode: 70300\n",
      "loss: 0.11306849122047424, episode: 70400\n",
      "loss: 0.17634086310863495, episode: 70500\n",
      "loss: 0.10488621890544891, episode: 70600\n",
      "loss: 0.2732512652873993, episode: 70700\n",
      "loss: 0.10321200639009476, episode: 70800\n",
      "loss: 0.16928631067276, episode: 70900\n",
      "loss: 0.04884858429431915, episode: 71000\n",
      "loss: 0.10782894492149353, episode: 71100\n",
      "loss: 0.4090835154056549, episode: 71200\n",
      "loss: 0.13730420172214508, episode: 71300\n",
      "loss: 0.11258884519338608, episode: 71400\n",
      "loss: 0.04121674224734306, episode: 71500\n",
      "loss: 0.24955879151821136, episode: 71600\n",
      "loss: 0.090507373213768, episode: 71700\n",
      "loss: 0.22456838190555573, episode: 71800\n",
      "loss: 0.17468968033790588, episode: 71900\n",
      "loss: 0.07894125580787659, episode: 72000\n",
      "loss: 0.11925879120826721, episode: 72100\n",
      "loss: 0.08091548085212708, episode: 72200\n",
      "loss: 0.13651981949806213, episode: 72300\n",
      "loss: 0.0891476422548294, episode: 72400\n",
      "loss: 0.14203353226184845, episode: 72500\n",
      "loss: 0.46505627036094666, episode: 72600\n",
      "loss: 0.10819642245769501, episode: 72700\n",
      "loss: 0.1346268206834793, episode: 72800\n",
      "loss: 0.09291556477546692, episode: 72900\n",
      "loss: 0.07178284227848053, episode: 73000\n",
      "loss: 0.20108845829963684, episode: 73100\n",
      "loss: 0.052989277988672256, episode: 73200\n",
      "loss: 0.1267947554588318, episode: 73300\n",
      "loss: 0.2030232548713684, episode: 73400\n",
      "loss: 0.07801956683397293, episode: 73500\n",
      "loss: 0.20963126420974731, episode: 73600\n",
      "loss: 0.0411883145570755, episode: 73700\n",
      "loss: 0.15349824726581573, episode: 73800\n",
      "loss: 0.11520741134881973, episode: 73900\n",
      "loss: 0.054479874670505524, episode: 74000\n",
      "loss: 0.10622578114271164, episode: 74100\n",
      "loss: 0.24407033622264862, episode: 74200\n",
      "loss: 0.07727979123592377, episode: 74300\n",
      "loss: 0.14167854189872742, episode: 74400\n",
      "loss: 0.07018367201089859, episode: 74500\n",
      "loss: 0.0733240470290184, episode: 74600\n",
      "loss: 0.3405318260192871, episode: 74700\n",
      "loss: 0.07135763019323349, episode: 74800\n",
      "loss: 0.14617560803890228, episode: 74900\n",
      "loss: 0.10955400764942169, episode: 75000\n",
      "loss: 0.25932615995407104, episode: 75100\n",
      "loss: 0.1865588128566742, episode: 75200\n",
      "loss: 0.03750372305512428, episode: 75300\n",
      "loss: 0.03493783622980118, episode: 75400\n",
      "loss: 0.32089847326278687, episode: 75500\n",
      "loss: 0.08093158900737762, episode: 75600\n",
      "loss: 0.27086904644966125, episode: 75700\n",
      "loss: 0.06497891247272491, episode: 75800\n",
      "loss: 0.17697158455848694, episode: 75900\n",
      "loss: 0.1467653512954712, episode: 76000\n",
      "loss: 0.22595937550067902, episode: 76100\n",
      "loss: 0.20063775777816772, episode: 76200\n",
      "loss: 0.09404589235782623, episode: 76300\n",
      "loss: 0.0644807294011116, episode: 76400\n",
      "loss: 0.06604202091693878, episode: 76500\n",
      "loss: 0.1565702259540558, episode: 76600\n",
      "loss: 0.054097533226013184, episode: 76700\n",
      "loss: 0.08325609564781189, episode: 76800\n",
      "loss: 0.15140940248966217, episode: 76900\n",
      "loss: 0.20675474405288696, episode: 77000\n",
      "loss: 0.10353083908557892, episode: 77100\n",
      "loss: 0.03306351602077484, episode: 77200\n",
      "loss: 0.09040354937314987, episode: 77300\n",
      "loss: 0.2521578073501587, episode: 77400\n",
      "loss: 0.31111350655555725, episode: 77500\n",
      "loss: 0.04197070002555847, episode: 77600\n",
      "loss: 0.10274995118379593, episode: 77700\n",
      "loss: 0.07243211567401886, episode: 77800\n",
      "loss: 0.36904385685920715, episode: 77900\n",
      "loss: 0.053972914814949036, episode: 78000\n",
      "loss: 0.12656979262828827, episode: 78100\n",
      "loss: 0.06114572286605835, episode: 78200\n",
      "loss: 0.05022953450679779, episode: 78300\n",
      "loss: 0.055811118334531784, episode: 78400\n",
      "loss: 0.0345093235373497, episode: 78500\n",
      "loss: 0.045780133455991745, episode: 78600\n",
      "loss: 0.05737173557281494, episode: 78700\n",
      "loss: 0.16162820160388947, episode: 78800\n",
      "loss: 0.10016307234764099, episode: 78900\n",
      "loss: 0.2324388474225998, episode: 79000\n",
      "loss: 0.04581895470619202, episode: 79100\n",
      "loss: 0.14458917081356049, episode: 79200\n",
      "loss: 0.13966995477676392, episode: 79300\n",
      "loss: 0.2182721346616745, episode: 79400\n",
      "loss: 0.0949159562587738, episode: 79500\n",
      "loss: 0.374187171459198, episode: 79600\n",
      "loss: 0.049902744591236115, episode: 79700\n",
      "loss: 0.05438690260052681, episode: 79800\n",
      "loss: 0.07144046574831009, episode: 79900\n",
      "loss: 0.0824139416217804, episode: 80000\n",
      "loss: 0.052052825689315796, episode: 80100\n",
      "loss: 0.15239553153514862, episode: 80200\n",
      "loss: 0.2974804937839508, episode: 80300\n",
      "loss: 0.03691555932164192, episode: 80400\n",
      "loss: 0.3442184031009674, episode: 80500\n",
      "loss: 0.24722427129745483, episode: 80600\n",
      "loss: 0.06473420560359955, episode: 80700\n",
      "loss: 0.17915895581245422, episode: 80800\n",
      "loss: 0.220197394490242, episode: 80900\n",
      "loss: 0.1276574432849884, episode: 81000\n",
      "loss: 0.054057829082012177, episode: 81100\n",
      "loss: 0.0504101924598217, episode: 81200\n",
      "loss: 0.2995906472206116, episode: 81300\n",
      "loss: 0.32388144731521606, episode: 81400\n",
      "loss: 0.13578742742538452, episode: 81500\n",
      "loss: 0.11755546927452087, episode: 81600\n",
      "loss: 0.07601787149906158, episode: 81700\n",
      "loss: 0.1834748387336731, episode: 81800\n",
      "loss: 0.06789128482341766, episode: 81900\n",
      "loss: 0.1999061405658722, episode: 82000\n",
      "loss: 0.14102351665496826, episode: 82100\n",
      "loss: 0.06407755613327026, episode: 82200\n",
      "loss: 0.19929350912570953, episode: 82300\n",
      "loss: 0.34564781188964844, episode: 82400\n",
      "loss: 0.1534867137670517, episode: 82500\n",
      "loss: 0.23153267800807953, episode: 82600\n",
      "loss: 0.23931141197681427, episode: 82700\n",
      "loss: 0.20658740401268005, episode: 82800\n",
      "loss: 0.09269984066486359, episode: 82900\n",
      "loss: 0.09439264237880707, episode: 83000\n",
      "loss: 0.17464753985404968, episode: 83100\n",
      "loss: 0.19317317008972168, episode: 83200\n",
      "loss: 0.12118470668792725, episode: 83300\n",
      "loss: 0.1931869238615036, episode: 83400\n",
      "loss: 0.33457261323928833, episode: 83500\n",
      "loss: 0.31463301181793213, episode: 83600\n",
      "loss: 0.05591466650366783, episode: 83700\n",
      "loss: 0.21535101532936096, episode: 83800\n",
      "loss: 0.07124757021665573, episode: 83900\n",
      "loss: 0.10346463322639465, episode: 84000\n",
      "loss: 0.12884780764579773, episode: 84100\n",
      "loss: 0.14690692722797394, episode: 84200\n",
      "loss: 0.13613863289356232, episode: 84300\n",
      "loss: 0.21673649549484253, episode: 84400\n",
      "loss: 0.40049242973327637, episode: 84500\n",
      "loss: 0.1609499156475067, episode: 84600\n",
      "loss: 0.051385194063186646, episode: 84700\n",
      "loss: 0.1746504008769989, episode: 84800\n",
      "loss: 0.18679466843605042, episode: 84900\n",
      "loss: 0.17314475774765015, episode: 85000\n",
      "loss: 0.07880840450525284, episode: 85100\n",
      "loss: 0.042919427156448364, episode: 85200\n",
      "loss: 0.19647136330604553, episode: 85300\n",
      "loss: 0.043596379458904266, episode: 85400\n",
      "loss: 0.08183300495147705, episode: 85500\n",
      "loss: 0.07599088549613953, episode: 85600\n",
      "loss: 0.21776488423347473, episode: 85700\n",
      "loss: 0.04368054121732712, episode: 85800\n",
      "loss: 0.13481423258781433, episode: 85900\n",
      "loss: 0.09681487083435059, episode: 86000\n",
      "loss: 0.08178026974201202, episode: 86100\n",
      "loss: 0.06724180281162262, episode: 86200\n",
      "loss: 0.05732166767120361, episode: 86300\n",
      "New best reward 23.000000000000043 in Episode 86337 - Model saved\n",
      "New best reward 23.100000000000044 in Episode 86337 - Model saved\n",
      "New best reward 23.200000000000045 in Episode 86337 - Model saved\n",
      "New best reward 23.300000000000047 in Episode 86337 - Model saved\n",
      "New best reward 23.40000000000005 in Episode 86337 - Model saved\n",
      "loss: 0.07266516983509064, episode: 86400\n",
      "loss: 0.1597360372543335, episode: 86500\n",
      "loss: 0.04002898931503296, episode: 86600\n",
      "loss: 0.15455961227416992, episode: 86700\n",
      "loss: 0.0974743440747261, episode: 86800\n",
      "loss: 0.03779522702097893, episode: 86900\n",
      "loss: 0.18888601660728455, episode: 87000\n",
      "loss: 0.10645893961191177, episode: 87100\n",
      "loss: 0.0613742396235466, episode: 87200\n",
      "loss: 0.2726144790649414, episode: 87300\n",
      "loss: 0.31142550706863403, episode: 87400\n",
      "loss: 0.1847572922706604, episode: 87500\n",
      "loss: 0.12513279914855957, episode: 87600\n",
      "loss: 0.17032495141029358, episode: 87700\n",
      "loss: 0.2774409055709839, episode: 87800\n",
      "loss: 0.23973508179187775, episode: 87900\n",
      "loss: 0.17298361659049988, episode: 88000\n",
      "loss: 0.08618926256895065, episode: 88100\n",
      "loss: 0.18007539212703705, episode: 88200\n",
      "loss: 0.12298864126205444, episode: 88300\n",
      "loss: 0.14926981925964355, episode: 88400\n",
      "loss: 0.1526298224925995, episode: 88500\n",
      "loss: 0.14020206034183502, episode: 88600\n",
      "loss: 0.15324725210666656, episode: 88700\n",
      "loss: 0.3646427094936371, episode: 88800\n",
      "loss: 0.259103000164032, episode: 88900\n",
      "loss: 0.23181772232055664, episode: 89000\n",
      "New best reward 23.40000000000006 in Episode 89017 - Model saved\n",
      "New best reward 23.400000000000066 in Episode 89017 - Model saved\n",
      "New best reward 23.500000000000068 in Episode 89017 - Model saved\n",
      "New best reward 23.60000000000007 in Episode 89017 - Model saved\n",
      "New best reward 23.70000000000007 in Episode 89017 - Model saved\n",
      "New best reward 23.80000000000007 in Episode 89017 - Model saved\n",
      "New best reward 23.900000000000073 in Episode 89017 - Model saved\n",
      "New best reward 24.000000000000075 in Episode 89017 - Model saved\n",
      "New best reward 24.100000000000076 in Episode 89017 - Model saved\n",
      "New best reward 24.200000000000077 in Episode 89017 - Model saved\n",
      "New best reward 24.30000000000008 in Episode 89017 - Model saved\n",
      "New best reward 24.40000000000008 in Episode 89017 - Model saved\n",
      "New best reward 24.50000000000008 in Episode 89017 - Model saved\n",
      "New best reward 24.600000000000083 in Episode 89017 - Model saved\n",
      "New best reward 24.700000000000085 in Episode 89017 - Model saved\n",
      "New best reward 24.800000000000086 in Episode 89017 - Model saved\n",
      "New best reward 24.900000000000087 in Episode 89017 - Model saved\n",
      "New best reward 25.00000000000009 in Episode 89017 - Model saved\n",
      "New best reward 25.000000000000103 in Episode 89017 - Model saved\n",
      "New best reward 26.000000000000103 in Episode 89017 - Model saved\n",
      "New best reward 26.100000000000104 in Episode 89017 - Model saved\n",
      "New best reward 26.200000000000106 in Episode 89017 - Model saved\n",
      "New best reward 26.200000000000113 in Episode 89017 - Model saved\n",
      "New best reward 26.300000000000114 in Episode 89017 - Model saved\n",
      "New best reward 26.400000000000116 in Episode 89017 - Model saved\n",
      "New best reward 26.500000000000117 in Episode 89017 - Model saved\n",
      "New best reward 26.60000000000012 in Episode 89017 - Model saved\n",
      "New best reward 26.70000000000012 in Episode 89017 - Model saved\n",
      "New best reward 26.80000000000012 in Episode 89017 - Model saved\n",
      "New best reward 26.900000000000123 in Episode 89017 - Model saved\n",
      "New best reward 27.000000000000124 in Episode 89017 - Model saved\n",
      "New best reward 27.100000000000126 in Episode 89017 - Model saved\n",
      "New best reward 27.200000000000127 in Episode 89017 - Model saved\n",
      "New best reward 27.30000000000013 in Episode 89017 - Model saved\n",
      "New best reward 27.40000000000013 in Episode 89017 - Model saved\n",
      "New best reward 27.50000000000013 in Episode 89017 - Model saved\n",
      "New best reward 27.600000000000133 in Episode 89017 - Model saved\n",
      "New best reward 27.700000000000134 in Episode 89017 - Model saved\n",
      "New best reward 27.800000000000136 in Episode 89017 - Model saved\n",
      "New best reward 27.900000000000137 in Episode 89017 - Model saved\n",
      "New best reward 28.00000000000014 in Episode 89017 - Model saved\n",
      "New best reward 28.10000000000014 in Episode 89017 - Model saved\n",
      "New best reward 28.20000000000014 in Episode 89017 - Model saved\n",
      "New best reward 28.20000000000015 in Episode 89017 - Model saved\n",
      "New best reward 28.70000000000015 in Episode 89017 - Model saved\n",
      "New best reward 28.700000000000163 in Episode 89017 - Model saved\n",
      "New best reward 28.800000000000164 in Episode 89017 - Model saved\n",
      "New best reward 28.900000000000166 in Episode 89017 - Model saved\n",
      "New best reward 29.000000000000167 in Episode 89017 - Model saved\n",
      "New best reward 29.10000000000017 in Episode 89017 - Model saved\n",
      "New best reward 29.20000000000017 in Episode 89017 - Model saved\n",
      "New best reward 29.30000000000017 in Episode 89017 - Model saved\n",
      "New best reward 29.400000000000173 in Episode 89017 - Model saved\n",
      "New best reward 29.500000000000174 in Episode 89017 - Model saved\n",
      "New best reward 29.600000000000176 in Episode 89017 - Model saved\n",
      "New best reward 29.700000000000177 in Episode 89017 - Model saved\n",
      "loss: 0.30100202560424805, episode: 89100\n",
      "loss: 0.18437999486923218, episode: 89200\n",
      "loss: 0.16111063957214355, episode: 89300\n",
      "loss: 0.05006943643093109, episode: 89400\n",
      "loss: 0.06690336763858795, episode: 89500\n",
      "loss: 0.16405773162841797, episode: 89600\n",
      "loss: 0.03409893438220024, episode: 89700\n",
      "loss: 0.28556135296821594, episode: 89800\n",
      "loss: 0.050548255443573, episode: 89900\n",
      "loss: 0.1282619684934616, episode: 90000\n",
      "loss: 0.06753098964691162, episode: 90100\n",
      "loss: 0.05282338708639145, episode: 90200\n",
      "loss: 0.3844829797744751, episode: 90300\n",
      "loss: 0.21287968754768372, episode: 90400\n",
      "loss: 0.26964521408081055, episode: 90500\n",
      "loss: 0.44398781657218933, episode: 90600\n",
      "loss: 0.1840040683746338, episode: 90700\n",
      "loss: 0.06972752511501312, episode: 90800\n",
      "loss: 0.1724243462085724, episode: 90900\n",
      "loss: 0.3654898405075073, episode: 91000\n",
      "loss: 0.03466273844242096, episode: 91100\n",
      "loss: 0.24690762162208557, episode: 91200\n",
      "loss: 0.19351844489574432, episode: 91300\n",
      "loss: 0.025116335600614548, episode: 91400\n",
      "loss: 0.1496240347623825, episode: 91500\n",
      "loss: 0.2070125937461853, episode: 91600\n",
      "loss: 0.37736499309539795, episode: 91700\n",
      "loss: 0.09499640762805939, episode: 91800\n",
      "loss: 0.26558738946914673, episode: 91900\n",
      "loss: 0.08540648221969604, episode: 92000\n",
      "loss: 0.21626976132392883, episode: 92100\n",
      "loss: 0.12239895761013031, episode: 92200\n",
      "loss: 0.1685381531715393, episode: 92300\n",
      "loss: 0.2494136542081833, episode: 92400\n",
      "loss: 0.10489639639854431, episode: 92500\n",
      "loss: 0.04876940697431564, episode: 92600\n",
      "loss: 0.06430882215499878, episode: 92700\n",
      "loss: 0.11873988807201385, episode: 92800\n",
      "loss: 0.19088903069496155, episode: 92900\n",
      "loss: 0.5257472991943359, episode: 93000\n",
      "loss: 0.03895064443349838, episode: 93100\n",
      "loss: 0.05060956999659538, episode: 93200\n",
      "loss: 0.14587968587875366, episode: 93300\n",
      "loss: 0.0870012491941452, episode: 93400\n",
      "loss: 0.07554073631763458, episode: 93500\n",
      "loss: 0.10080482065677643, episode: 93600\n",
      "loss: 0.2397216558456421, episode: 93700\n",
      "loss: 0.17289157211780548, episode: 93800\n",
      "loss: 0.25049877166748047, episode: 93900\n",
      "loss: 0.13254058361053467, episode: 94000\n",
      "loss: 0.25795286893844604, episode: 94100\n",
      "loss: 0.057479143142700195, episode: 94200\n",
      "loss: 0.25471779704093933, episode: 94300\n",
      "loss: 0.1423344612121582, episode: 94400\n",
      "loss: 0.29909950494766235, episode: 94500\n",
      "loss: 0.21968664228916168, episode: 94600\n",
      "loss: 0.1442379653453827, episode: 94700\n",
      "loss: 0.27856481075286865, episode: 94800\n",
      "loss: 0.06438314914703369, episode: 94900\n",
      "loss: 0.1119837686419487, episode: 95000\n",
      "loss: 0.11910264194011688, episode: 95100\n",
      "loss: 0.0773572325706482, episode: 95200\n",
      "loss: 0.2217339426279068, episode: 95300\n",
      "loss: 0.06521175801753998, episode: 95400\n",
      "loss: 0.05570511892437935, episode: 95500\n",
      "loss: 0.19549226760864258, episode: 95600\n",
      "loss: 0.05908399820327759, episode: 95700\n",
      "loss: 0.06946519017219543, episode: 95800\n",
      "loss: 0.07684844732284546, episode: 95900\n",
      "loss: 0.08339431881904602, episode: 96000\n",
      "loss: 0.20899073779582977, episode: 96100\n",
      "loss: 0.07566708326339722, episode: 96200\n",
      "loss: 0.03931567817926407, episode: 96300\n",
      "loss: 0.05454263836145401, episode: 96400\n",
      "loss: 0.09822770208120346, episode: 96500\n",
      "loss: 0.06302936375141144, episode: 96600\n",
      "loss: 0.046359602361917496, episode: 96700\n",
      "loss: 0.3626040816307068, episode: 96800\n",
      "loss: 0.24743716418743134, episode: 96900\n",
      "loss: 0.04934137314558029, episode: 97000\n",
      "loss: 0.11844664812088013, episode: 97100\n",
      "loss: 0.16975702345371246, episode: 97200\n",
      "loss: 0.1766364574432373, episode: 97300\n",
      "loss: 0.2474317103624344, episode: 97400\n",
      "loss: 0.06242015212774277, episode: 97500\n",
      "loss: 0.2012314349412918, episode: 97600\n",
      "loss: 0.11477349698543549, episode: 97700\n",
      "loss: 0.13885867595672607, episode: 97800\n",
      "loss: 0.21544739603996277, episode: 97900\n",
      "loss: 0.3126448690891266, episode: 98000\n",
      "loss: 0.07416846603155136, episode: 98100\n",
      "loss: 0.22248756885528564, episode: 98200\n",
      "loss: 0.23604971170425415, episode: 98300\n",
      "loss: 0.16640564799308777, episode: 98400\n",
      "loss: 0.16750210523605347, episode: 98500\n",
      "loss: 0.039443615823984146, episode: 98600\n",
      "loss: 0.17404747009277344, episode: 98700\n",
      "loss: 0.23769620060920715, episode: 98800\n",
      "loss: 0.03354734554886818, episode: 98900\n",
      "loss: 0.06831751763820648, episode: 99000\n",
      "loss: 0.37625017762184143, episode: 99100\n",
      "loss: 0.08173274993896484, episode: 99200\n",
      "loss: 0.03338497877120972, episode: 99300\n",
      "loss: 0.045498646795749664, episode: 99400\n",
      "loss: 0.06363658607006073, episode: 99500\n",
      "loss: 0.10908697545528412, episode: 99600\n",
      "loss: 0.24146106839179993, episode: 99700\n",
      "loss: 0.21573904156684875, episode: 99800\n",
      "loss: 0.11413216590881348, episode: 99900\n",
      "loss: 0.14477625489234924, episode: 100000\n",
      "loss: 0.12981146574020386, episode: 100100\n",
      "loss: 0.09526939690113068, episode: 100200\n",
      "loss: 0.23401430249214172, episode: 100300\n",
      "loss: 0.19753962755203247, episode: 100400\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n",
      "Error in callback <function _draw_all_if_interactive at 0x00000221EEB21E10> (for post_execute):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\xiang\\AppData\\Local\\Temp\\ipykernel_22692\\234809708.py\", line 3, in <module>\n",
      "    agent.run(is_train=True, is_render=False, use_saved_model=False)\n",
      "  File \"d:\\RL_Finance\\RL sutton book\\flappy bird\\agent.py\", line 172, in run\n",
      "    self.save_graph(reward_per_episode)\n",
      "  File \"d:\\RL_Finance\\RL sutton book\\flappy bird\\agent.py\", line 204, in save_graph\n",
      "    fig.savefig(self.GRAPH_FILE)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py\", line 3395, in savefig\n",
      "    self.canvas.print_figure(fname, **kwargs)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\", line 2204, in print_figure\n",
      "    result = print_method(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\", line 2054, in <lambda>\n",
      "    print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\", line 496, in print_png\n",
      "    self._print_pil(filename_or_obj, \"png\", pil_kwargs, metadata)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\", line 444, in _print_pil\n",
      "    FigureCanvasAgg.draw(self)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\", line 387, in draw\n",
      "    self.figure.draw(self.renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 95, in draw_wrapper\n",
      "    result = draw(artist, renderer, *args, **kwargs)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py\", line 3162, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\", line 3137, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\legend.py\", line 777, in draw\n",
      "    self._legend_box.draw(renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 39, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\offsetbox.py\", line 380, in draw\n",
      "    px, py = self.get_offset(bbox, renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\offsetbox.py\", line 60, in get_offset\n",
      "    return meth(params[\"self\"], bbox, params[\"renderer\"])\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\offsetbox.py\", line 306, in get_offset\n",
      "    self._offset(bbox.width, bbox.height, -bbox.x0, -bbox.y0, renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\legend.py\", line 735, in _findoffset\n",
      "    x, y = self._find_best_position(width, height, renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\legend.py\", line 1167, in _find_best_position\n",
      "    bboxes, lines, offsets = self._auto_legend_data()\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\legend.py\", line 971, in _auto_legend_data\n",
      "    artist.get_transform().transform_path(artist.get_path()))\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 1610, in transform_path\n",
      "    return self.transform_path_affine(self.transform_path_non_affine(path))\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 1620, in transform_path_affine\n",
      "    return self.get_affine().transform_path_affine(path)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 1812, in transform_path_affine\n",
      "    return Path(self.transform_affine(path.vertices),\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\", line 300, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 1865, in transform_affine\n",
      "    return affine_transform(values, mtx)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.53 MiB for an array with shape (100460, 2) and data type float64\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 317, in executing\n",
      "    args = executing_cache[key]\n",
      "KeyError: (<code object run_code at 0x00000221BCAB4B30, file \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3424>, 2343922518832, 76)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 799, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 854, in get_records\n",
      "    return list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 565, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\stack_data\\utils.py\", line 84, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 555, in mapper\n",
      "    return cls(f, options)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 520, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 369, in executing\n",
      "    args = find(source=cls.for_frame(frame), retry_cache=True)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 252, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 270, in for_filename\n",
      "    result = source_cache[filename] = cls._for_filename_and_lines(filename, lines)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 281, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 79, in __init__\n",
      "    super(Source, self).__init__(*args, **kwargs)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 228, in __init__\n",
      "    self.tree = ast.parse(ast_text, filename=filename)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\ast.py\", line 50, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "MemoryError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\events.py\", line 89, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\", line 268, in _draw_all_if_interactive\n",
      "    draw_all()\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\_pylab_helpers.py\", line 131, in draw_all\n",
      "    manager.canvas.draw_idle()\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\", line 1905, in draw_idle\n",
      "    self.draw(*args, **kwargs)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\", line 387, in draw\n",
      "    self.figure.draw(self.renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 95, in draw_wrapper\n",
      "    result = draw(artist, renderer, *args, **kwargs)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py\", line 3162, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\", line 3137, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\lines.py\", line 759, in draw\n",
      "    self._transform_path(subslice)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\lines.py\", line 725, in _transform_path\n",
      "    _path = Path(np.asarray(xy).T,\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.53 MiB for an array with shape (2, 100460) and data type float64\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 317, in executing\n",
      "    args = executing_cache[key]\n",
      "KeyError: (<code object _draw_all_if_interactive at 0x00000221EDE4F260, file \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\", line 266>, 2344748380768, 10)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 799, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 854, in get_records\n",
      "    return list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 565, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\stack_data\\utils.py\", line 84, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 555, in mapper\n",
      "    return cls(f, options)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 520, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 369, in executing\n",
      "    args = find(source=cls.for_frame(frame), retry_cache=True)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 252, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 270, in for_filename\n",
      "    result = source_cache[filename] = cls._for_filename_and_lines(filename, lines)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 281, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 79, in __init__\n",
      "    super(Source, self).__init__(*args, **kwargs)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 228, in __init__\n",
      "    self.tree = ast.parse(ast_text, filename=filename)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\ast.py\", line 50, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "MemoryError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\", line 221, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\", line 338, in __call__\n",
      "    return printer(obj)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\", line 152, in print_figure\n",
      "    fig.canvas.print_figure(bytes_io, **kw)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\", line 2175, in print_figure\n",
      "    self.figure.draw(renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 95, in draw_wrapper\n",
      "    result = draw(artist, renderer, *args, **kwargs)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py\", line 3162, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\", line 3137, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 72, in draw_wrapper\n",
      "    return draw(artist, renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\legend.py\", line 766, in draw\n",
      "    bbox = self._legend_box.get_window_extent(renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\offsetbox.py\", line 369, in get_window_extent\n",
      "    px, py = self.get_offset(bbox, renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\offsetbox.py\", line 60, in get_offset\n",
      "    return meth(params[\"self\"], bbox, params[\"renderer\"])\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\offsetbox.py\", line 306, in get_offset\n",
      "    self._offset(bbox.width, bbox.height, -bbox.x0, -bbox.y0, renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\legend.py\", line 735, in _findoffset\n",
      "    x, y = self._find_best_position(width, height, renderer)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\legend.py\", line 1167, in _find_best_position\n",
      "    bboxes, lines, offsets = self._auto_legend_data()\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\legend.py\", line 971, in _auto_legend_data\n",
      "    artist.get_transform().transform_path(artist.get_path()))\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 1610, in transform_path\n",
      "    return self.transform_path_affine(self.transform_path_non_affine(path))\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 1620, in transform_path_affine\n",
      "    return self.get_affine().transform_path_affine(path)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 1812, in transform_path_affine\n",
      "    return Path(self.transform_affine(path.vertices),\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\", line 300, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 1865, in transform_affine\n",
      "    return affine_transform(values, mtx)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.53 MiB for an array with shape (100460, 2) and data type float64\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 317, in executing\n",
      "    args = executing_cache[key]\n",
      "KeyError: (<code object print_figure at 0x00000221EE5A33C0, file \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\", line 2063>, 2344756065216, 474)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 799, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 854, in get_records\n",
      "    return list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 565, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\stack_data\\utils.py\", line 84, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 555, in mapper\n",
      "    return cls(f, options)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 520, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 369, in executing\n",
      "    args = find(source=cls.for_frame(frame), retry_cache=True)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 252, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 270, in for_filename\n",
      "    result = source_cache[filename] = cls._for_filename_and_lines(filename, lines)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 281, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 81, in __init__\n",
      "    self.asttokens()\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 413, in asttokens\n",
      "    return ASTTokens(\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\asttokens\\asttokens.py\", line 59, in __init__\n",
      "    self._tokens = list(self._generate_tokens(source_text))\n",
      "  File \"c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\asttokens\\asttokens.py\", line 85, in _generate_tokens\n",
      "    for index, tok in enumerate(tokenize.generate_tokens(io.StringIO(text).readline)):\n",
      "MemoryError\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agent import Agent\n",
    "agent = Agent(\"flappybird\")\n",
    "agent.run(is_train=True, is_render=False, use_saved_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RL_Finance\\RL sutton book\\flappy bird\\agent.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  policy_qnet.load_state_dict(torch.load(self.MODEL_FILE))  # Load trained weights\n",
      "c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "c:\\Users\\xiang\\anaconda3\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = 37.200000000000735\n",
      "Episode 2: Total Reward = 63.800000000000495\n",
      "Episode 3: Total Reward = 38.40000000000069\n"
     ]
    }
   ],
   "source": [
    "from agent import Agent\n",
    "agent = Agent(\"flappybird\")\n",
    "agent.play(num_episodes=3, is_render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
